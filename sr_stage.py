#!/usr/bin/env python
# SRé˜¶æ®µå¤„ç†è„šæœ¬ - åˆ†ç¦»å¼ä¸¤é˜¶æ®µæ¨ç†æ–¹æ¡ˆ

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

import numpy as np
import tensorflow as tf
import tensorlayer as tl
import tifffile
import argparse
import cv2
from tensorlayer.layers import InputLayer

# å¯¼å…¥é¡¹ç›®é…ç½®å’Œæ¨¡å‹
from config import config
from model.F_VCD import F_Denoise
from utils import normalize_percentile

def read_valid_npy_images(path):
    img_list = sorted([f for f in os.listdir(path) if f.endswith('.npy')])
    if not img_list:
        raise FileNotFoundError(f"âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .npy éªŒè¯æ•°æ®: {path}")
    imgs = []
    names = []
    for fn in img_list:
        data = np.load(os.path.join(path, fn)).astype(np.float32)
        if data.ndim == 2:
            data = np.expand_dims(data, axis=-1)
        imgs.append(normalize_percentile(data))  # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„normalize_percentileå½’ä¸€åŒ–æ–¹æ³•
        names.append(fn)
    imgs = np.stack(imgs, axis=0)  # [N, H, W, V]
    print(f"âœ… åŠ è½½ {len(img_list)} å¼ éªŒè¯å›¾, shape = {imgs.shape}")
    return imgs, names

def sr_inference(epoch=0, batch_size=1):
    """SRé˜¶æ®µï¼šLFè¾“å…¥ â†’ SRç½‘ç»œ â†’ ä¿å­˜SRè¾“å‡º"""
    epoch_tag = 'best' if epoch == 0 else f'epoch{epoch}'
    ckpt_dir = config.TRAIN.ckpt_dir
    valid_path = config.VALID.lf2d_path
    save_dir = config.VALID.saving_path
    os.makedirs(save_dir, exist_ok=True)
    sr_temp_dir = os.path.join(save_dir, 'sr_outputs')
    os.makedirs(sr_temp_dir, exist_ok=True)

    # 1) è¯»å–éªŒè¯æ•°æ®
    valid_imgs, names = read_valid_npy_images(valid_path)
    H, W = valid_imgs.shape[1], valid_imgs.shape[2]
    SR_size = np.array([H, W]) * config.img_setting.sr_factor

    # 2) æ„å»ºSRç½‘ç»œ
    tf.reset_default_graph()
    t_image = tf.placeholder(tf.float32, [batch_size, H, W, config.img_setting.Nnum], name='t_LFP')
    with tf.device(f"/gpu:{config.TRAIN.device}"):
        inp_layer = InputLayer(t_image, name='input_layer')
        SR_net = F_Denoise(
            inp_layer, output_size=SR_size,
            angRes=config.img_setting.Nnum,
            sr_factor=config.img_setting.sr_factor,
            reuse=False, name=config.net_setting.SR_model,
            channels_interp=config.channels_interp,
            normalize_mode=config.preprocess.normalize_mode
        )
    
    # 3) æŸ¥æ‰¾å’ŒåŠ è½½SRæƒé‡
    def find_ckpt(model_name):
        # é¦–å…ˆæŸ¥æ‰¾å¸¦æœ‰_structuredçš„æ–‡ä»¶
        cand = [f for f in os.listdir(ckpt_dir)
                if f.endswith('_structured.npz') and epoch_tag in f and model_name in f]
        if not cand:
            alias = 'SR_net' if 'F_Denoise' in model_name else 'recon_net'
            cand = [f for f in os.listdir(ckpt_dir)
                    if f.endswith('_structured.npz') and epoch_tag in f and alias in f]
        # å¦‚æœæ‰¾ä¸åˆ°_structuredæ–‡ä»¶ï¼Œåˆ™æŸ¥æ‰¾æ™®é€š.npzæ–‡ä»¶
        if not cand:
            cand = [f for f in os.listdir(ckpt_dir)
                    if f.endswith('.npz') and epoch_tag in f and model_name in f]
        if not cand:
            cand = [f for f in os.listdir(ckpt_dir)
                    if f.endswith('.npz') and epoch_tag in f and 
                    ('SR_net' if 'F_Denoise' in model_name else 'recon_net') in f]
        if not cand:
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° {model_name} çš„æƒé‡æ–‡ä»¶ ({epoch_tag})")
        return os.path.join(ckpt_dir, cand[0])

    # å…³é”®ä¿®å¤ï¼šç¡®ä¿è°ƒç”¨find_ckptå‡½æ•°å¹¶èµ‹å€¼ç»™sr_ckpt
    sr_ckpt = find_ckpt(config.net_setting.SR_model)
    print("ğŸ“‚ SR æƒé‡è·¯å¾„:", sr_ckpt)

    # 4) ä¼šè¯ä¸è½½æƒ
    sess_config = tf.ConfigProto(allow_soft_placement=True)
    sess_config.gpu_options.allow_growth = True
    sess = tf.Session(config=sess_config)
    sess.run(tf.global_variables_initializer())

    # ä¿®æ”¹ï¼šæ‰‹åŠ¨åŠ è½½æƒé‡ï¼Œä¸ä½¿ç”¨TensorLayerçš„è¾…åŠ©å‡½æ•°
    sr_npz = np.load(sr_ckpt, allow_pickle=True)
    matched_sr = 0
    for var in SR_net.all_params:
        key = var.name  # åŒ…å«":0"
        if key in sr_npz:
            sess.run(var.assign(sr_npz[key]))
            matched_sr += 1
        else:
            # å°è¯•æ›¿ä»£åç§°æ ¼å¼
            alt_key = key.split(':')[0]  # å»æ‰":0"åç¼€
            if alt_key in sr_npz:
                sess.run(var.assign(sr_npz[alt_key]))
                matched_sr += 1
            else:
                print(f"âš ï¸ SR_net: æœªåœ¨ npz ä¸­æ‰¾åˆ°å˜é‡ {key}")
    print(f"âœ… SR_net æˆåŠŸåŠ è½½ {matched_sr}/{len(SR_net.all_params)} ä¸ªå‚æ•°")

    # æ£€æŸ¥NaNå€¼
    has_nan = False
    for v in SR_net.all_params[:5]:  # åªæ£€æŸ¥å‰5ä¸ªæƒé‡é¿å…è¿‡å¤šè¾“å‡º
        arr = sess.run(v)
        print(f"[SR PARAM] {v.name:30s} mean={arr.mean():.6f}, std={arr.std():.6f}")
        if np.isnan(arr).any():
            has_nan = True
            print(f"âš ï¸ è­¦å‘Š: {v.name} ä¸­å‘ç°NaNå€¼!")
    
    if has_nan:
        print("âš ï¸ è­¦å‘Š: å‘ç°NaNæƒé‡! æ¨¡å‹å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    
    # 5) æ‰¹é‡æ¨ç†å’Œä¿å­˜
    name_mapping_file = os.path.join(sr_temp_dir, 'name_mapping.txt')
    with open(name_mapping_file, 'w') as f:
        for idx in range(len(valid_imgs)):
            # å¤„ç†ä¸€æ‰¹æ¬¡æ•°æ®
            batch = valid_imgs[idx:idx+batch_size]
            sr_out = sess.run(SR_net.outputs, feed_dict={t_image: batch})
            
            # ä¿å­˜SRè¾“å‡º
            sr_filename = f'sr_output_{idx:04d}.tif'
            sr_save_path = os.path.join(sr_temp_dir, sr_filename)
            tifffile.imwrite(sr_save_path, sr_out[0])
            
            # è®°å½•æ˜ å°„å…³ç³»
            f.write(f"{names[idx]},{sr_filename}\n")
            
            # æ˜¾ç¤ºè¿›åº¦
            print(f"\rå¤„ç†SR {idx+1}/{len(valid_imgs)}", end='')
    
    print(f"\nâœ… SRé˜¶æ®µå®Œæˆ! è¾“å‡ºä¿å­˜åœ¨: {sr_temp_dir}")
    print(f"ğŸ“ æ˜ å°„æ–‡ä»¶: {name_mapping_file}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='SRé˜¶æ®µæ¨ç†è„šæœ¬')
    parser.add_argument('--ckpt', type=int, default=0, help='0è¡¨ç¤ºbestï¼Œå¦åˆ™è¡¨ç¤ºepochç¼–å·')
    parser.add_argument('--batch', type=int, default=1, help='æ¨ç†æ—¶batch size')
    args = parser.parse_args()
    
    # è®¾ç½®GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = str(config.TRAIN.device)
    
    sr_inference(epoch=args.ckpt, batch_size=args.batch)