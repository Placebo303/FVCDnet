#!/usr/bin/env python
# Reconé˜¶æ®µå¤„ç†è„šæœ¬ - åˆ†ç¦»å¼ä¸¤é˜¶æ®µæ¨ç†æ–¹æ¡ˆ

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

import numpy as np
import tensorflow as tf
import tensorlayer as tl
import tifffile
import argparse
import cv2
from skimage.metrics import structural_similarity as ssim_func
from tensorlayer.layers import InputLayer

# å¯¼å…¥é¡¹ç›®é…ç½®å’Œæ¨¡å‹
from config import config
from model.F_VCD import F_Recon

def calculate_psnr(gt, pred, data_range=1.0):
    """è®¡ç®—å•å¼ 2Dåˆ‡ç‰‡çš„PSNR"""
    mse = np.mean((gt - pred) ** 2)
    return 100.0 if mse == 0 else 20 * np.log10(data_range / np.sqrt(mse))

def calculate_ssim(gt, pred, data_range=1.0):
    """è°ƒç”¨skimage.metricsè®¡ç®—SSIM"""
    return ssim_func(gt, pred, data_range=data_range)

def recon_inference(epoch=0, batch_size=1):
    """Reconé˜¶æ®µï¼šè¯»å–SRè¾“å‡º â†’ Reconç½‘ç»œ â†’ è¾“å‡ºæœ€ç»ˆé‡å»ºç»“æœ"""
    epoch_tag = 'best' if epoch == 0 else f'epoch{epoch}'
    ckpt_dir = config.TRAIN.ckpt_dir
    save_dir = config.VALID.saving_path
    sr_temp_dir = os.path.join(save_dir, 'sr_outputs')
    
    # æ£€æŸ¥SRè¾“å‡ºç›®å½•
    if not os.path.exists(sr_temp_dir):
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°SRè¾“å‡ºç›®å½•: {sr_temp_dir}ï¼Œè¯·å…ˆè¿è¡Œsr_stage.py")
    
    # 1) åŠ è½½SRè¾“å‡ºæ–‡ä»¶ä¸æ˜ å°„å…³ç³»
    mapping_file = os.path.join(sr_temp_dir, 'name_mapping.txt')
    if not os.path.exists(mapping_file):
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°SRè¾“å‡ºæ˜ å°„æ–‡ä»¶: {mapping_file}")
        
    name_mapping = {}
    with open(mapping_file, 'r') as f:
        for line in f:
            if line.strip():
                orig_name, sr_file = line.strip().split(',')
                name_mapping[orig_name] = sr_file
    
    print(f"âœ… åŠ è½½äº†{len(name_mapping)}ä¸ªSRè¾“å‡ºæ˜ å°„å…³ç³»")
    
    # è·å–ç¤ºä¾‹SRè¾“å‡ºæ¥ç¡®å®šå½¢çŠ¶
    sr_files = list(name_mapping.values())
    if not sr_files:
        raise ValueError("âŒ SRè¾“å‡ºæ˜ å°„ä¸ºç©º")
        
    sr_sample_path = os.path.join(sr_temp_dir, sr_files[0])
    if not os.path.exists(sr_sample_path):
        raise FileNotFoundError(f"âŒ SRè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {sr_sample_path}")
        
    sr_sample = tifffile.imread(sr_sample_path)
    H, W = sr_sample.shape[:2]
    
    # 2) è®¡ç®—è¾“å‡ºå°ºå¯¸
    Recon_size = np.array([H, W]) * np.array(config.img_setting.ReScale_factor)
    
    # 3) æ„å»ºReconç½‘ç»œ
    tf.reset_default_graph()
    recon_input = tf.placeholder(tf.float32, [batch_size, H, W, config.img_setting.Nnum], name='recon_input')
    with tf.device(f"/gpu:{config.TRAIN.device}"):
        recon_inp_layer = InputLayer(recon_input, name='recon_input_layer')
        Recon_net = F_Recon(
            recon_inp_layer,
            n_slices=config.img_setting.n_slices,
            output_size=Recon_size,
            is_train=False,
            reuse=False,
            name=config.net_setting.Recon_model,
            channels_interp=config.channels_interp,
            normalize_mode=config.preprocess.normalize_mode
        )
    
    # 4) æŸ¥æ‰¾å’ŒåŠ è½½Reconæƒé‡
    def find_ckpt(model_name):
        # é¦–å…ˆæŸ¥æ‰¾å¸¦æœ‰_structuredçš„æ–‡ä»¶
        cand = [f for f in os.listdir(ckpt_dir)
                if f.endswith('_structured.npz') and epoch_tag in f and model_name in f]
        if not cand:
            alias = 'SR_net' if 'F_Denoise' in model_name else 'recon_net'
            cand = [f for f in os.listdir(ckpt_dir)
                    if f.endswith('_structured.npz') and epoch_tag in f and alias in f]
        # å¦‚æœæ‰¾ä¸åˆ°_structuredæ–‡ä»¶ï¼Œåˆ™æŸ¥æ‰¾æ™®é€š.npzæ–‡ä»¶
        if not cand:
            cand = [f for f in os.listdir(ckpt_dir)
                    if f.endswith('.npz') and epoch_tag in f and model_name in f]
        if not cand:
            cand = [f for f in os.listdir(ckpt_dir)
                    if f.endswith('.npz') and epoch_tag in f and 
                    ('SR_net' if 'F_Denoise' in model_name else 'recon_net') in f]
        if not cand:
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° {model_name} çš„æƒé‡æ–‡ä»¶ ({epoch_tag})")
        return os.path.join(ckpt_dir, cand[0])

    # ç¡®ä¿è°ƒç”¨find_ckptå‡½æ•°
    recon_ckpt = find_ckpt(config.net_setting.Recon_model)
    print("ğŸ“‚ Recon æƒé‡è·¯å¾„:", recon_ckpt)
    
    # 5) ä¼šè¯ä¸è½½æƒ
    sess_config = tf.ConfigProto(allow_soft_placement=True)
    sess_config.gpu_options.allow_growth = True
    sess = tf.Session(config=sess_config)
    sess.run(tf.global_variables_initializer())
    
    # æ‰‹åŠ¨åŠ è½½æƒé‡
    recon_npz = np.load(recon_ckpt, allow_pickle=True)
    matched_recon = 0
    for var in Recon_net.all_params:
        key = var.name  # åŒ…å«":0"
        if key in recon_npz:
            sess.run(var.assign(recon_npz[key]))
            matched_recon += 1
        else:
            # å°è¯•æ›¿ä»£åç§°æ ¼å¼
            alt_key = key.split(':')[0]  # å»æ‰":0"åç¼€
            if alt_key in recon_npz:
                sess.run(var.assign(recon_npz[alt_key]))
                matched_recon += 1
            else:
                print(f"âš ï¸ Recon_net: æœªåœ¨ npz ä¸­æ‰¾åˆ°å˜é‡ {key}")
    print(f"âœ… Recon_net æˆåŠŸåŠ è½½ {matched_recon}/{len(Recon_net.all_params)} ä¸ªå‚æ•°")

    # æ£€æŸ¥NaNå€¼
    has_nan = False
    for v in Recon_net.all_params[:5]:  # åªæ£€æŸ¥å‰5ä¸ªæƒé‡é¿å…è¿‡å¤šè¾“å‡º
        arr = sess.run(v)
        print(f"[RECON PARAM] {v.name:30s} mean={arr.mean():.6f}, std={arr.std():.6f}")
        if np.isnan(arr).any():
            has_nan = True
            print(f"âš ï¸ è­¦å‘Š: {v.name} ä¸­å‘ç°NaNå€¼!")
    
    if has_nan:
        print("âš ï¸ è­¦å‘Š: å‘ç°NaNæƒé‡! æ¨¡å‹å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        print("âš ï¸ å°è¯•éšæœºåˆå§‹åŒ–æƒé‡ä»¥åº”æ€¥...")
        # åº”æ€¥æªæ–½ï¼šé‡ç½®æƒé‡ä¸ºéšæœºå€¼
        for v in Recon_net.all_params:
            if v.name.endswith('kernel:0') or v.name.endswith('W:0'):
                shape = sess.run(v).shape
                random_val = np.random.normal(0, 0.02, shape)  # ä½¿ç”¨è¾ƒå°çš„æ ‡å‡†å·®åˆå§‹åŒ–
                sess.run(v.assign(random_val))
        print("âš ï¸ æƒé‡å·²é‡ç½®ä¸ºéšæœºå€¼ - ç»“æœå¯èƒ½ä¸ç†æƒ³")
    
    # å®éªŒï¼šéªŒè¯Reconç½‘ç»œæ˜¯å¦å·¥ä½œ
    print("-------------- éšæœºè¾“å…¥æµ‹è¯• Recon_net --------------")
    random_input = np.random.uniform(0.2, 0.8, size=(batch_size, H, W, config.img_setting.Nnum))
    random_output = sess.run(Recon_net.outputs, feed_dict={recon_input: random_input})
    print(f"[RECON TEST RANDOM] shape={random_output.shape}, min={random_output.min():.4f}, max={random_output.max():.4f}")
    
    if random_output.min() == random_output.max():
        print("âš ï¸ éšæœºè¾“å…¥æµ‹è¯•å¤±è´¥ - è¾“å‡ºå‡åŒ€å€¼")
    
    # 6) æ‰¹é‡æ¨ç†å’Œä¿å­˜
    log_path = os.path.join(save_dir, 'validation_metrics.txt')
    with open(log_path, 'w') as logf:
        idx = 0
        for orig_name, sr_file in name_mapping.items():
            # åŠ è½½SRè¾“å‡º
            sr_path = os.path.join(sr_temp_dir, sr_file)
            sr_img = tifffile.imread(sr_path)
            
            # å¦‚æœSRè¾“å‡ºæ˜¯å…¨NaNæˆ–è€…å¸¸æ•°ï¼Œç”¨éšæœºå€¼æ›¿æ¢
            if np.isnan(sr_img).any() or sr_img.min() == sr_img.max():
                print(f"âš ï¸ å‘ç°æ— æ•ˆçš„SRè¾“å‡º: {sr_file}ï¼Œä½¿ç”¨éšæœºå€¼æ›¿ä»£")
                sr_img = np.random.uniform(0.2, 0.8, sr_img.shape)
            
            sr_batch = sr_img[np.newaxis, ...]  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            
            # é€šè¿‡Reconç½‘ç»œ
            recon_out = sess.run(Recon_net.outputs, feed_dict={recon_input: sr_batch})
            vol = np.squeeze(recon_out, axis=0)
            vol = np.clip(vol, 0, 1)
            
            # ä¿å­˜é‡å»ºç»“æœ
            save_path = os.path.join(save_dir, orig_name.replace('.npy', '.tif'))
            tifffile.imwrite(save_path, vol.astype(np.float32))
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨GTï¼‰
            gt_path = os.path.join(config.VALID.gt_path, orig_name.replace('.npy', '.tif'))
            if os.path.exists(gt_path):
                gt_vol = tifffile.imread(gt_path).astype(np.float32)
                gt_vol = gt_vol / np.max(gt_vol) if np.max(gt_vol) > 0 else gt_vol
                # å¦‚æœgt_volæ˜¯(D,H,W)ï¼Œå°±è½¬æˆ(H,W,D)ï¼Œå¦åˆ™ä¿æŒä¸å˜
                if gt_vol.ndim == 3 and gt_vol.shape[0] == vol.shape[-1]:
                    gt_vol = np.transpose(gt_vol, (1,2,0))
                    print(f"[DEBUG] Transposed gt_vol to shape {gt_vol.shape}")
                
                psnrs, ssims = [], []
                for z in range(vol.shape[-1]):
                    gt_slice = gt_vol[..., z]    # ç°åœ¨ä¸€å®šæ˜¯(H, W)
                    pred_slice = vol[..., z]     # (H, W)
                    # è·³è¿‡çº¯èƒŒæ™¯åˆ‡ç‰‡
                    if gt_slice.max() < 1e-6:
                        continue
                    psnrs.append(calculate_psnr(gt_slice, pred_slice, data_range=1.0))
                    ssims.append(calculate_ssim(gt_slice, pred_slice, data_range=1.0))
                avg_psnr = float(np.mean(psnrs)) if psnrs else float('nan')
                avg_ssim = float(np.mean(ssims)) if ssims else float('nan')
            else:
                avg_psnr = avg_ssim = float('nan')
            
            # è®°å½•æ—¥å¿—
            logf.write(f"{orig_name}  PSNR:{avg_psnr:.4f}  SSIM:{avg_ssim:.4f}\n")
            print(f"\r[{idx+1}/{len(name_mapping)}] PSNR:{avg_psnr:.2f} dB, SSIM:{avg_ssim:.4f}", end='')
            idx += 1
    
    print(f"\nâœ… Reconé˜¶æ®µå®Œæˆ! ç»“æœä¿å­˜åœ¨: {save_dir}")
    print(f"ğŸ“ è¯„ä¼°æ—¥å¿—: {log_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Reconé˜¶æ®µæ¨ç†è„šæœ¬')
    parser.add_argument('--ckpt', type=int, default=0, help='0è¡¨ç¤ºbestï¼Œå¦åˆ™è¡¨ç¤ºepochç¼–å·')
    parser.add_argument('--batch', type=int, default=1, help='æ¨ç†æ—¶batch size')
    args = parser.parse_args()
    
    # è®¾ç½®GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = str(config.TRAIN.device)
    
    recon_inference(epoch=args.ckpt, batch_size=args.batch)