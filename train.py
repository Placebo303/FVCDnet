# âœ… train_final.py -- ç¬¦åˆæ–°ç‰ˆF-VCDè®­ç»ƒè§„èŒƒï¼ˆå®Œæ•´ç‰ˆï¼‰

import os
import time
import json
import tensorflow as tf
import tensorlayer as tl
import numpy as np
import matplotlib.pyplot as plt
from model import *
from dataset_npy_loader import Dataset
from utils import write3d, normalize_percentile
from config import config
from tensorlayer.layers import InputLayer
os.environ['CUDA_VISIBLE_DEVICES'] = str(config.TRAIN.device)

# ================= å›¾åƒä¸è®­ç»ƒå‚æ•° ====================
img_size = config.img_setting.img_size
n_num = config.img_setting.Nnum
sr_factor = config.img_setting.sr_factor
n_slices = config.img_setting.n_slices
ReScale_factor = config.img_setting.ReScale_factor
channels_interp = config.channels_interp
normalize_mode = config.preprocess.normalize_mode

batch_size = config.TRAIN.batch_size
lr_init = config.TRAIN.lr_init
beta1 = config.TRAIN.beta1
n_epoch = config.TRAIN.n_epoch
lr_decay = config.TRAIN.lr_decay
decay_every = config.TRAIN.decay_every

sample_ratio = config.TRAIN.sample_ratio
shuffle_for_epoch = config.TRAIN.shuffle_for_epoch

checkpoint_dir = config.TRAIN.ckpt_dir
log_dir = config.TRAIN.log_dir
test_saving_dir = config.TRAIN.test_saving_path
plot_test_loss_dir = os.path.join(test_saving_dir, 'test_loss_plt')
test_hr_dir = os.path.join(test_saving_dir, 'HR_View')
test_lf_dir = os.path.join(test_saving_dir, 'LFP')
test_stack_dir = os.path.join(test_saving_dir, 'Target3D')

label = config.label
SR_loss = config.Loss.SR_loss
Recon_loss = config.Loss.Recon_loss
loss_ratio = config.Loss.Ratio

save_hyperparameters = True

# ================ å·¥å…·å‡½æ•° ==================
def weighted_mae_loss(image, reference):
    # æ·»åŠ æ•°å€¼ç¨³å®šæ€§çš„å°å¸¸æ•°
    epsilon = 1e-8
    # è£å‰ªä»¥é¿å…æç«¯å€¼
    image = tf.clip_by_value(image, 0.0, 1.0)
    reference = tf.clip_by_value(reference, 0.0, 1.0)
    weight = tf.abs(reference) + epsilon
    diff = tf.abs(image - reference)
    # è£å‰ªæç«¯å·®å¼‚å€¼
    diff = tf.clip_by_value(diff, 0.0, 1.0)
    loss = tf.reduce_mean(weight * diff)
    return loss

def weighted_mse_loss(image, reference):
    # æ·»åŠ æ•°å€¼ç¨³å®šæ€§çš„å°å¸¸æ•°
    epsilon = 1e-8
    # è£å‰ªä»¥é¿å…æç«¯å€¼
    image = tf.clip_by_value(image, 0.0, 1.0)
    reference = tf.clip_by_value(reference, 0.0, 1.0)
    weight = tf.abs(reference) + epsilon
    diff = tf.square(image - reference)
    # è£å‰ªæç«¯å·®å¼‚å€¼
    diff = tf.clip_by_value(diff, 0.0, 1.0)
    loss = tf.reduce_mean(weight * diff)
    return loss

def edge_loss(image, reference):
    def _gradient(x):
        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§çš„å°å¸¸æ•°
        epsilon = 1e-7
        x = tf.clip_by_value(x, epsilon, 1.0)
        gx = x[:, :-1, :, :] - x[:, 1:, :, :]
        gy = x[:, :, :-1, :] - x[:, :, 1:, :]
        # è£å‰ªæ¢¯åº¦å€¼é¿å…æç«¯å€¼
        gx = tf.clip_by_value(gx, -0.5, 0.5)
        gy = tf.clip_by_value(gy, -0.5, 0.5)
        return gx, gy

    gx_i, gy_i = _gradient(image)
    gx_r, gy_r = _gradient(reference)

    # è£å‰ªæˆç»Ÿä¸€å°ºå¯¸
    min_h = tf.minimum(tf.shape(gx_i)[1], tf.shape(gx_r)[1])
    min_w = tf.minimum(tf.shape(gx_i)[2], tf.shape(gx_r)[2])

    gx_i = tf.image.resize_with_crop_or_pad(gx_i, min_h, min_w)
    gx_r = tf.image.resize_with_crop_or_pad(gx_r, min_h, min_w)
    gy_i = tf.image.resize_with_crop_or_pad(gy_i, min_h, min_w)
    gy_r = tf.image.resize_with_crop_or_pad(gy_r, min_h, min_w)

    # è®¡ç®—å·®å¼‚æ—¶æ·»åŠ æ›´å¤šçš„æ•°å€¼ä¿æŠ¤
    diff_x = tf.clip_by_value(tf.abs(gx_i - gx_r), 0.0, 0.5) 
    diff_y = tf.clip_by_value(tf.abs(gy_i - gy_r), 0.0, 0.5)
    loss = tf.reduce_mean(diff_x + diff_y)
    return loss

def is_number(x):
    try:
        float(x)
        return True
    except ValueError:
        return False

class Trainer:
    def __init__(self, dataset):
        self.dataset = dataset
        self.losses = {}
        self.test_loss_plt = []

    def build_graph(self):
        # â€”â€” åŠ¨æ€å­¦ä¹ ç‡å˜é‡ â€”â€” 
        with tf.variable_scope('learning_rate'):
            self.learning_rate = tf.Variable(config.TRAIN.lr_init, trainable=False)

        # â€”â€” å›¾åƒå°ºå¯¸è®¡ç®— â€”â€” 
        input_size  = np.array([config.img_setting.img_size, config.img_setting.img_size])
        SR_size     = input_size * config.img_setting.sr_factor
        Recon_size  = np.multiply(SR_size, config.img_setting.ReScale_factor)

        # â€”â€” å ä½ç¬¦å®šä¹‰ â€”â€” 
        self.plchdr_lf         = tf.placeholder('float32', [config.TRAIN.batch_size, *input_size, config.img_setting.Nnum], name='t_LFP')
        self.plchdr_SynView    = tf.placeholder('float32', [config.TRAIN.batch_size, *SR_size,     config.img_setting.Nnum], name='t_SynView')
        self.plchdr_target3d   = tf.placeholder('float32', [config.TRAIN.batch_size, *Recon_size,  config.img_setting.n_slices], name='t_target3d')

        # â€”â€” GPU è®¾å¤‡ï¼Œä¸Šä¸‹æ–‡å†…ä¿æŒç½‘ç»œé“¾å®Œæ•´ â€”â€” 
        with tf.device(f"/gpu:{config.TRAIN.device}"):
            # 1) ç”¨ InputLayer åŒ…è£… LF è¾“å…¥  
            lf_input = InputLayer(self.plchdr_lf, name='input_LF')

            # 2) æ„å»º SR å­ç½‘  
            self.SR_net = F_Denoise(
                lf_input,
                SR_size,
                angRes=config.img_setting.Nnum,
                sr_factor=config.img_setting.sr_factor,
                reuse=False,
                name=config.net_setting.SR_model,
                channels_interp=config.channels_interp,
                normalize_mode=config.preprocess.normalize_mode
            )
            self.SR_net.print_params(False)

            # 3) æ„å»º Recon å­ç½‘ï¼Œç›´æ¥ä¼ å…¥ Layer  
            self.Recon_net = F_Recon(
                self.SR_net,
                config.img_setting.n_slices,
                Recon_size,
                reuse=False,
                name=config.net_setting.Recon_model,
                channels_interp=config.channels_interp,
                normalize_mode=config.preprocess.normalize_mode
            )
            self.Recon_net.print_params(False)

        # â€”â€” å˜é‡åˆ—è¡¨ â€”â€” 
        SR_vars    = tl.layers.get_variables_with_name(config.net_setting.SR_model,   train_only=True, printable=False)
        Recon_vars = tl.layers.get_variables_with_name(config.net_setting.Recon_model, train_only=True, printable=False)

        # â€”â€” æŸå¤±è®¡ç®— â€”â€” 
        self.SR_loss    = 0.0
        self.Recon_loss = 0.0

        # 2.1) SR é˜¶æ®µ  
        for key, weight in config.Loss.SR_loss.items():                    
            fn       = globals()[key]
            tmp_loss = tf.clip_by_value(
                fn(image=self.SR_net.outputs, reference=self.plchdr_SynView),
                clip_value_min=1e-8, clip_value_max=1e4
            )
            self.SR_loss += weight * tmp_loss
            self.losses[f"SR_{key}"] = weight * tmp_loss
            tf.summary.scalar(f"SR_{key}", tmp_loss)

        # 2.2) Recon é˜¶æ®µ  
        for key, weight in config.Loss.Recon_loss.items():                 
            fn       = globals()[key]
            tmp_loss = tf.clip_by_value(
                fn(image=self.Recon_net.outputs, reference=self.plchdr_target3d),
                clip_value_min=1e-8, clip_value_max=1e8
            )
            self.Recon_loss += weight * tmp_loss
            self.losses[f"Recon_{key}"] = weight * tmp_loss
            tf.summary.scalar(f"Recon_{key}", tmp_loss)

        # 2.3) æ€»æŸå¤±  
        sr_w, recon_w = config.Loss.Ratio                                 
        self.loss     = sr_w * self.SR_loss + recon_w * self.Recon_loss
        self.losses['total_loss'] = self.loss
        tf.summary.scalar('total_loss', self.loss)
        tf.summary.scalar('learning_rate', self.learning_rate)

        # â€”â€” Session & TensorBoard â€”â€” 
        configProto = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
        configProto.gpu_options.allow_growth = True
        self.sess = tf.Session(config=configProto)

        self.merge_op      = tf.summary.merge_all()
        self.summary_writer = tf.summary.FileWriter(config.TRAIN.log_dir, self.sess.graph)

        # â€”â€” ä¼˜åŒ–å™¨ï¼ˆå¢åŠ æ¢¯åº¦è£å‰ªï¼‰ â€”â€” 
        with tf.variable_scope('optimizer'):
            # SRä¼˜åŒ–å™¨ - æ·»åŠ æ¢¯åº¦è£å‰ª
            sr_optimizer = tf.train.AdamOptimizer(self.learning_rate, beta1=config.TRAIN.beta1, epsilon=1e-8)
            sr_grads_and_vars = sr_optimizer.compute_gradients(self.SR_loss, var_list=SR_vars)
            sr_clipped_grads_and_vars = [(tf.clip_by_value(grad, -1.0, 1.0), var) 
                                     for grad, var in sr_grads_and_vars if grad is not None]
            self.SR_optim = sr_optimizer.apply_gradients(sr_clipped_grads_and_vars)

            # Reconä¼˜åŒ–å™¨ - æ·»åŠ æ¢¯åº¦è£å‰ª
            recon_optimizer = tf.train.AdamOptimizer(self.learning_rate, beta1=config.TRAIN.beta1, epsilon=1e-8)
            recon_grads_and_vars = recon_optimizer.compute_gradients(self.loss, var_list=SR_vars + Recon_vars)
            recon_clipped_grads_and_vars = [(tf.clip_by_value(grad, -1.0, 1.0), var) 
                                        for grad, var in recon_grads_and_vars if grad is not None]
            self.Recon_optim = recon_optimizer.apply_gradients(recon_clipped_grads_and_vars)

        # â€”â€” å‚æ•°æ‰“å°ï¼ˆå¯é€‰ï¼‰ â€”â€” 
        print("ğŸ” SR_net å‚æ•°æ€»æ•°:", len(SR_vars))
        print("ğŸ” Recon_net å‚æ•°æ€»æ•°:", len(Recon_vars))
        print("ğŸ” SR_net å‚æ•°åˆ—è¡¨:")
        for v in SR_vars: print("   ", v.name)
        print("ğŸ” Recon_net å‚æ•°åˆ—è¡¨:")
        for v in Recon_vars: print("   ", v.name)

    def _train(self, begin_epoch):
        tl.files.exists_or_mkdir(test_saving_dir)
        tl.files.exists_or_mkdir(checkpoint_dir)
        tl.files.exists_or_mkdir(log_dir)
        tl.files.exists_or_mkdir(plot_test_loss_dir)

        self.sess.run(tf.global_variables_initializer())
        self.sess.run(tf.assign(self.learning_rate, lr_init))
        # ğŸ”¥ã€é¢„çƒ­é€»è¾‘ã€‘é¦–æ¬¡æ‰§è¡Œä¸€æ¬¡å›¾ï¼Œé¿å…cuDNNåˆå§‹åŒ–å¡é¡¿
        print("ğŸ”¥ æ­£åœ¨æ‰§è¡Œé¢„çƒ­æ“ä½œ...")

        dummy_lf = np.zeros([batch_size, img_size, img_size, n_num], dtype=np.float32)
        dummy_syn = np.zeros([batch_size, img_size, img_size, n_num], dtype=np.float32)
        dummy_stack = np.zeros([batch_size, img_size * ReScale_factor[0], img_size * ReScale_factor[1], n_slices], dtype=np.float32)

        feed_warmup = {
            self.plchdr_lf: dummy_lf,
            self.plchdr_SynView: dummy_syn,
            self.plchdr_target3d: dummy_stack,
        }

        _ = self.sess.run(self.losses, feed_dict=feed_warmup)
        print("âœ… é¢„çƒ­å®Œæˆï¼Œæ­£å¼è¿›å…¥è®­ç»ƒé˜¶æ®µã€‚")
        epoch_total_loss = 0
        epoch_step_count = 0
        # ğŸ” åŠ è½½æ–­ç‚¹Checkpointï¼ˆæ ¹æ®begin_epochï¼‰
        ckpt_tag = 'epoch{}'.format(begin_epoch)
        sr_ckpt = os.path.join(checkpoint_dir, f'SR_net_{ckpt_tag}.npz')
        recon_ckpt = os.path.join(checkpoint_dir, f'recon_net_{ckpt_tag}.npz')

        if os.path.exists(sr_ckpt):
            tl.files.load_and_assign_npz(sess=self.sess, name=sr_ckpt, network=self.SR_net)
            print(f"ğŸ” åŠ è½½ SR checkpoint: {sr_ckpt}")
        if os.path.exists(recon_ckpt):
            tl.files.load_and_assign_npz(sess=self.sess, name=recon_ckpt, network=self.Recon_net)
            print(f"ğŸ” åŠ è½½ Recon checkpoint: {recon_ckpt}")
    
        if save_hyperparameters:
            self._save_training_settings()

        dataset_size = self.dataset.prepare(batch_size, n_epoch)
        final_cursor = (dataset_size // batch_size - 1) * batch_size

        while self.dataset.hasNext():
            Stack_batch, HR_batch, LF_batch, cursor, epoch = self.dataset.iter()
            epoch += begin_epoch
            step_start_time = time.time()

            if epoch != 0 and (epoch % decay_every == 0) and cursor == 0:
                new_lr_decay = lr_decay ** (epoch // decay_every)
                self.sess.run(tf.assign(self.learning_rate, lr_init * new_lr_decay))
                print(f"\nğŸ” å­¦ä¹ ç‡è¡°å‡åˆ°: {lr_init * new_lr_decay:.8f}")

            feed_train = {
                self.plchdr_target3d: Stack_batch,
                self.plchdr_SynView: HR_batch,
                self.plchdr_lf: LF_batch,
            }

            evaluated = self.sess.run({**self.losses, 'opti_sr': self.SR_optim, 'opti_recon': self.Recon_optim, 'batch_summary': self.merge_op}, feed_train)
            loss_str = [name + ":" + f"{value:.6f}" for name, value in evaluated.items() if 'loss' in name]
            epoch_total_loss += evaluated['total_loss']
            epoch_step_count += 1
            print(f"\rEpoch:[{epoch}/{n_epoch+begin_epoch}] iter:[{cursor}/{dataset_size}] time: {time.time() - step_start_time:.3f}s {time.strftime('%Y-%m-%d %H:%M:%S')} --- {loss_str}", end='')
            
            # æ£€æŸ¥NaNå¹¶å°è¯•æ¢å¤
            has_nan = False
            for name, value in evaluated.items():
                if 'loss' in name and (np.isnan(value) or np.isinf(value)):
                    print(f"\nâš ï¸ æ£€æµ‹åˆ°NaN/InfæŸå¤±: {name}={value}! Epoch:{epoch}, Iter:{cursor}")
                    has_nan = True
                    break

            if has_nan:
                print("âš ï¸ å°è¯•ä»ä¸Šä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤...")
                # æ¢å¤åˆ°æœ€è¿‘çš„æ£€æŸ¥ç‚¹
                last_good_epoch = (epoch // config.TRAIN.ckpt_saving_interval) * config.TRAIN.ckpt_saving_interval
                if last_good_epoch == epoch:  # å¦‚æœå½“å‰epochæ˜¯ä¿å­˜ç‚¹ï¼Œå›é€€ä¸€ä¸ªé—´éš”
                    last_good_epoch = max(0, last_good_epoch - config.TRAIN.ckpt_saving_interval)

                # æ¢å¤ä»£ç ...
                last_sr_ckpt = os.path.join(checkpoint_dir, f'SR_net_epoch{last_good_epoch}.npz')
                last_recon_ckpt = os.path.join(checkpoint_dir, f'recon_net_epoch{last_good_epoch}.npz')

                if os.path.exists(last_sr_ckpt) and os.path.exists(last_recon_ckpt):
                    tl.files.load_and_assign_npz(sess=self.sess, name=last_sr_ckpt, network=self.SR_net)
                    tl.files.load_and_assign_npz(sess=self.sess, name=last_recon_ckpt, network=self.Recon_net)
                    print(f"âœ… æˆåŠŸæ¢å¤åˆ°epoch {last_good_epoch}")
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰bestæ¨¡å‹
                    best_sr_ckpt = os.path.join(checkpoint_dir, 'SR_net_best.npz')
                    best_recon_ckpt = os.path.join(checkpoint_dir, 'recon_net_best.npz')

                    if os.path.exists(best_sr_ckpt) and os.path.exists(best_recon_ckpt):
                        tl.files.load_and_assign_npz(sess=self.sess, name=best_sr_ckpt, network=self.SR_net)
                        tl.files.load_and_assign_npz(sess=self.sess, name=best_recon_ckpt, network=self.Recon_net)
                        print("âœ… å·²æ¢å¤åˆ°bestæ¨¡å‹")
                    else:
                        print("âŒ æ— æ³•æ‰¾åˆ°å¯æ¢å¤çš„æ£€æŸ¥ç‚¹ï¼Œç»§ç»­è®­ç»ƒä½†ç»“æœå¯èƒ½ä¸ç¨³å®š")
            self.summary_writer.add_summary(evaluated['batch_summary'], epoch * (dataset_size // batch_size - 1) + cursor // batch_size)

            if cursor == final_cursor:
                if (epoch % config.TRAIN.ckpt_saving_interval == 0):
                    self._save_intermediate_ckpt(epoch, self.sess)
                    self._plot_test_loss()
                with open(os.path.join(checkpoint_dir, "last_epoch.txt"), "w") as f:
                    f.write(str(epoch + 1))
                avg_loss = epoch_total_loss / epoch_step_count
                print(f"\nğŸ“‰ Epoch {epoch} å¹³å‡Loss: {avg_loss:.6f}")
                # é‡ç½®ç»Ÿè®¡å™¨
                epoch_total_loss = 0
                epoch_step_count = 0
                if not hasattr(self, 'best_loss') or avg_loss < self.best_loss:
                    self.best_loss = avg_loss
                    self._save_intermediate_ckpt('best', self.sess)
                    print(f"ğŸŒŸ å½“å‰æœ€ä¼˜ï¼Œä¿å­˜bestæ¨¡å‹ï¼(epoch {epoch}, avg_loss={avg_loss:.6f})")
                    
        print("\nâœ… è®­ç»ƒå®Œæˆï¼")

    def _save_training_settings(self):
        params = config.copy()
        if 'load' in params: del params['load']
        save_path = os.path.join(checkpoint_dir, 'train_setting.json')
        with open(save_path, 'w') as f:
            json.dump(params, f, indent=4)
        print(f"ğŸ“„ è®­ç»ƒè¶…å‚æ•°ä¿å­˜åˆ°: {save_path}")

    def _save_intermediate_ckpt(self, tag, sess):
        tag = ('epoch%d' % tag) if is_number(tag) else tag
        sr_file_name = os.path.join(checkpoint_dir, f'SR_net_{tag}.npz')
        recon_file_name = os.path.join(checkpoint_dir, f'recon_net_{tag}.npz')

        # âœ… å½»åº•æ›¿ä»£ all_paramsï¼Œä½¿ç”¨åå­—è¿‡æ»¤æ–¹å¼æå– SR/Recon ç½‘ç»œå˜é‡
        sr_vars = tl.layers.get_variables_with_name(config.net_setting.SR_model, train_only=True, printable=False)
        recon_vars = tl.layers.get_variables_with_name(config.net_setting.Recon_model, train_only=True, printable=False)

        # âœ… ä¿å­˜å˜é‡
        # âœ… ä¿å­˜ SR_net æƒé‡ï¼ˆç»“æ„åŒ–ï¼Œå˜é‡ååš keyï¼‰
        sr_params_dict = {var.name: sess.run(var) for var in sr_vars}
        np.savez(sr_file_name.replace(".npz", "_structured.npz"), **sr_params_dict)

        # âœ… ä¿å­˜ Recon_net æƒé‡ï¼ˆç»“æ„åŒ–ï¼Œå˜é‡ååš keyï¼‰
        recon_params_dict = {var.name: sess.run(var) for var in recon_vars}
        np.savez(recon_file_name.replace(".npz", "_structured.npz"), **recon_params_dict)
        print(f"ğŸ’¾ ä¿å­˜SR_net:{sr_file_name}, Recon_net:{recon_file_name}")
        with open(os.path.join(checkpoint_dir, 'SR_varnames.txt'), 'w') as f:
            f.write('\n'.join([var.name for var in sr_vars]))
        with open(os.path.join(checkpoint_dir, 'Recon_varnames.txt'), 'w') as f:
            f.write('\n'.join([var.name for var in recon_vars]))


        # è¡¥å……æ¨ç†ä¿å­˜SRå’ŒReconç»“æœ
        if hasattr(self, 'test_LFP'):
            test_batch = self.test_LFP[:batch_size]
            SR_view = self.sess.run(self.SR_net.outputs, {self.plchdr_lf: test_batch})
            Recon_stack = self.sess.run(self.Recon_net.outputs, {self.plchdr_lf: test_batch})
            for i in range(SR_view.shape[0]):
                write3d(SR_view[i:i+1], os.path.join(test_saving_dir, f'SR_{tag}_{i}.tif'))
                write3d(Recon_stack[i:i+1], os.path.join(test_saving_dir, f'Recon_{tag}_{i}.tif'))
            print(f"ğŸ“¤ å½“å‰epoch {tag} ä¿å­˜æ¨ç†SRä¸Reconå›¾åƒ")



    def _plot_test_loss(self):
        if len(self.test_loss_plt) == 0:
            return
        loss = np.asarray(self.test_loss_plt)
        plt.figure()
        plt.plot(loss[:, 0], loss[:, 1], marker='o')
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.title("Validation Loss")
        plt.grid(True)
        save_path = os.path.join(plot_test_loss_dir, 'test_loss.png')
        plt.savefig(save_path)
        np.save(os.path.join(plot_test_loss_dir, 'test_loss.npy'), np.array(self.test_loss_plt))
        plt.close()
        print(f"âœ… éªŒè¯é›†lossæ›²çº¿å·²ä¿å­˜: {save_path}")

    def train(self, **kwargs):
        try:
            self._train(**kwargs)
        finally:
            self._plot_test_loss()

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('-c', '--ckpt', type=int, default=0)
    args = parser.parse_args()

    resume_path = os.path.join(config.TRAIN.ckpt_dir, "last_epoch.txt")
    last_epoch = 0
    if os.path.exists(resume_path):
        with open(resume_path, "r") as f:
            content = f.read().strip()
            if content:
                last_epoch = int(content)

    begin_epoch = args.ckpt if args.ckpt > 0 else last_epoch

    dataset = Dataset(
        config.img_setting.Target3D,
        config.img_setting.Synth_view,
        config.img_setting.LFP,
        config.img_setting.Nnum,
        config.img_setting.img_size // config.img_setting.Nnum,
        n_slices=config.img_setting.n_slices,
        shuffle_for_epoch=shuffle_for_epoch,
        sample_ratio=sample_ratio
    )

    trainer = Trainer(dataset)
    trainer.build_graph()
    trainer.train(begin_epoch=begin_epoch)
