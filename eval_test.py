import os
import sys
sys.path.insert(0, os.path.dirname(__file__))

import numpy as np
import tensorflow as tf
import tensorlayer as tl
import tifffile
from skimage.metrics import structural_similarity as ssim_func
from skimage.transform import resize
from config import config                                  # é…ç½®æ–‡ä»¶è·¯å¾„ & å‚æ•°
from model.F_VCD import F_Denoise, F_Recon
from tensorlayer.layers import InputLayer
from utils import normalize_percentile
import cv2

os.environ['CUDA_VISIBLE_DEVICES'] = str(config.TRAIN.device)

def read_valid_npy_images(path):
    img_list = sorted([f for f in os.listdir(path) if f.endswith('.npy')])
    if not img_list:
        raise FileNotFoundError(f"âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .npy éªŒè¯æ•°æ®: {path}")
    imgs = []
    for fn in img_list:
        data = np.load(os.path.join(path, fn)).astype(np.float32)
        if data.ndim == 2:
            data = np.expand_dims(data, axis=-1)
        imgs.append(normalize_percentile(data))  # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„ normalize_percentile å½’ä¸€åŒ–æ–¹æ³•
    imgs = np.stack(imgs, axis=0)  # [N, H, W, V]
    print(f"âœ… åŠ è½½ {len(img_list)} å¼ éªŒè¯å›¾, shape = {imgs.shape}")
    return imgs, img_list

def calculate_psnr(gt, pred, data_range=1.0):
    """è®¡ç®—å•å¼  2D åˆ‡ç‰‡çš„ PSNR"""
    mse = np.mean((gt - pred) ** 2)
    return 100.0 if mse == 0 else 20 * np.log10(data_range / np.sqrt(mse))

def calculate_ssim(gt, pred, data_range=1.0):
    """è°ƒç”¨ skimage.metrics è®¡ç®— SSIM"""
    return ssim_func(gt, pred, data_range=data_range)

def infer(epoch=0, batch_size=1):
    """ä¸»æµç¨‹ï¼šæ„å›¾â†’è½½æƒé‡â†’æ‰¹é‡æ¨ç†â†’è®¡ç®—æŒ‡æ ‡å¹¶ä¿å­˜"""
    epoch_tag = 'best' if epoch == 0 else f'epoch{epoch}'
    ckpt_dir   = config.TRAIN.ckpt_dir
    valid_path = config.VALID.lf2d_path
    save_dir   = config.VALID.saving_path
    os.makedirs(save_dir, exist_ok=True)

    # 1) è¯»å–éªŒè¯é›†
    valid_imgs, names = read_valid_npy_images(valid_path)
    H, W = valid_imgs.shape[1], valid_imgs.shape[2]
    SR_size    = np.array([H, W]) * config.img_setting.sr_factor
    Recon_size = SR_size * np.array(config.img_setting.ReScale_factor)

    # 2) æ„å»ºåˆ†ç¦»çš„ç½‘ç»œå›¾ - é¿å…åµŒå¥—ä½œç”¨åŸŸé—®é¢˜
    tf.reset_default_graph()
    
    # === ç¬¬ä¸€é˜¶æ®µï¼šSRç½‘ç»œ ===
    sr_input = tf.placeholder(tf.float32, [batch_size, H, W, config.img_setting.Nnum], name='sr_input')
    with tf.device(f"/gpu:{config.TRAIN.device}"):
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†åˆ›å»ºé¢å¤–çš„ä½œç”¨åŸŸï¼Œç›´æ¥ä½¿ç”¨F_Denoiseå†…éƒ¨çš„ä½œç”¨åŸŸ
        sr_input_layer = InputLayer(sr_input, name='input_layer')
        sr_net = F_Denoise(
            sr_input_layer, output_size=SR_size,
            angRes=config.img_setting.Nnum,
            sr_factor=config.img_setting.sr_factor,
            reuse=False, name=config.net_setting.SR_model,
            channels_interp=config.channels_interp,
            normalize_mode=config.preprocess.normalize_mode
        )
        sr_output = sr_net.outputs  # è®°å½•SRè¾“å‡ºå¼ é‡
    
    # === ç¬¬äºŒé˜¶æ®µï¼šReconç½‘ç»œï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰ ===
    recon_input = tf.placeholder(tf.float32, [batch_size, H, W, config.img_setting.Nnum], name='recon_input')
    with tf.device(f"/gpu:{config.TRAIN.device}"):
        # åŒæ ·ä¸æ·»åŠ é¢å¤–ä½œç”¨åŸŸ
        recon_input_layer = InputLayer(recon_input, name='recon_input_layer')
        recon_net = F_Recon(
            recon_input_layer,
            n_slices=config.img_setting.n_slices,
            output_size=Recon_size,
            is_train=False,
            reuse=False,
            name=config.net_setting.Recon_model,
            channels_interp=config.channels_interp,
            normalize_mode=config.preprocess.normalize_mode
        )
        recon_output = recon_net.outputs  # è®°å½•Reconè¾“å‡ºå¼ é‡
    
    # 3) æŸ¥æ‰¾æƒé‡æ–‡ä»¶
    # è¿™éƒ¨åˆ†ä¿æŒä¸å˜...
    
    # 4) ä¼šè¯ä¸è½½æƒ
    sess_config = tf.ConfigProto(allow_soft_placement=True)
    sess_config.gpu_options.allow_growth = True
    sess = tf.Session(config=sess_config)
    sess.run(tf.global_variables_initializer())
    
    # åŠ è½½SR_netæƒé‡ - ä¿®å¤å˜é‡ååŒ¹é…é€»è¾‘
    sr_npz = np.load(sr_ckpt, allow_pickle=True)
    # ç°åœ¨ä»all_paramsè·å–å˜é‡è€Œä¸æ˜¯ç”¨ä½œç”¨åŸŸæ¥æ”¶é›†
    sr_vars = sr_net.all_params
    matched_sr = 0
    for var in sr_vars:
        # ä»var.nameä¸­å»é™¤:0åç¼€
        key = var.name.split(':')[0]
        if key in sr_npz:
            sess.run(var.assign(sr_npz[key]))
            matched_sr += 1
        else:
            # å°è¯•ä½¿ç”¨å¤‡é€‰åç§°æ ¼å¼
            alt_key = key.replace('F_Denoise/F_Denoise/', 'F_Denoise/')
            if alt_key in sr_npz:
                sess.run(var.assign(sr_npz[alt_key]))
                matched_sr += 1
            else:
                print(f"âš ï¸ SR_net: æœªåœ¨npzä¸­æ‰¾åˆ°å˜é‡ {key} æˆ– {alt_key}")
    print(f"âœ… SR_net æˆåŠŸåŠ è½½ {matched_sr}/{len(sr_vars)} ä¸ªå‚æ•°")

    # åŠ è½½Recon_netæƒé‡ - ä½¿ç”¨ç›¸åŒçš„ä¿®å¤é€»è¾‘
    recon_npz = np.load(recon_ckpt, allow_pickle=True)
    recon_vars = recon_net.all_params
    matched_recon = 0
    for var in recon_vars:
        key = var.name.split(':')[0]
        if key in recon_npz:
            sess.run(var.assign(recon_npz[key]))
            matched_recon += 1
        else:
            alt_key = key.replace('F_Recon/F_Recon/', 'F_Recon/')
            if alt_key in recon_npz:
                sess.run(var.assign(recon_npz[alt_key]))
                matched_recon += 1
            else:
                print(f"âš ï¸ Recon_net: æœªåœ¨npzä¸­æ‰¾åˆ°å˜é‡ {key} æˆ– {alt_key}")
    print(f"âœ… Recon_net æˆåŠŸåŠ è½½ {matched_recon}/{len(recon_vars)} ä¸ªå‚æ•°")
    
    # æ‰“å°æƒé‡å‰5ä¸ªå‚æ•°æ¥ç¡®è®¤æ˜¯å¦æ­£ç¡®åŠ è½½
    print("-------------- è°ƒè¯• Recon_net å‚æ•° --------------")
    for i, v in enumerate(recon_vars[:5]):
        arr = sess.run(v)
        print(f"[RECON PARAM {i}] {v.name:30s} mean={arr.mean():.6f}, std={arr.std():.6f}")

    # 5) ä¸¤é˜¶æ®µæ¨ç†è¿‡ç¨‹
    # 5.1) SRé˜¶æ®µ - å¤„ç†LFè¾“å…¥
    sr_result = sess.run(sr_output, feed_dict={sr_input: valid_imgs[0:1]})
    print(f"[SR STAGE] sr_result shape={sr_result.shape}, min={sr_result.min():.4f}, max={sr_result.max():.4f}")
    
    # ä¿å­˜SRè¾“å‡º
    sr_save_path = os.path.join(save_dir, 'sr_out.tif')
    tifffile.imwrite(sr_save_path, sr_result[0])
    
    # 5.2) Reconé˜¶æ®µ - å°†SRç»“æœä½œä¸ºè¾“å…¥
    # æ³¨ï¼šæ­¤å¤„å…ˆresizeå›åŸå§‹å°ºå¯¸
    H0, W0 = valid_imgs.shape[1], valid_imgs.shape[2]
    sr_resized = cv2.resize(
        sr_result[0], (W0, H0), 
        interpolation=cv2.INTER_LINEAR
    )[None, ...]  # å¢åŠ æ‰¹æ¬¡ç»´åº¦
    
    # éšæœºæµ‹è¯•è¾“å…¥
    random_input = np.random.uniform(0.2, 0.8, size=(1, H0, W0, config.img_setting.Nnum))
    random_result = sess.run(recon_output, feed_dict={recon_input: random_input})
    print(f"[RECON RANDOM] shape={random_result.shape}, min={random_result.min():.4f}, max={random_result.max():.4f}")
    
    # çœŸå®SRè¾“å‡ºä½œä¸ºè¾“å…¥
    recon_result = sess.run(recon_output, feed_dict={recon_input: sr_resized})
    print(f"[RECON STAGE] recon_result shape={recon_result.shape}, min={recon_result.min():.4f}, max={recon_result.max():.4f}")
    
    # ä¿å­˜Reconè¾“å‡º
    recon_save_path = os.path.join(save_dir, 'recon_out.tif')
    tifffile.imwrite(recon_save_path, recon_result[0])
    print(f"ğŸ“‚ ä¿å­˜å›¾åƒ: SR={sr_save_path}, Recon={recon_save_path}")

    # 6) æ‰¹é‡æ¨ç†ã€ä¿å­˜ tifã€è®¡ç®—å¹¶è®°å½• PSNR/SSIM
    log_path = os.path.join(save_dir, 'validation_metrics.txt')
    with open(log_path, 'w') as logf:
        for idx in range(len(valid_imgs)):
            batch = valid_imgs[idx:idx+batch_size]
            out = sess.run(Recon_net.outputs, feed_dict={t_image: batch})
            vol = np.squeeze(out, axis=0)
            vol = np.clip(vol, 0, 1)

            # ä¿å­˜é‡å»ºä½“æ•°æ®
            save_p = os.path.join(save_dir, names[idx].replace('.npy', '.tif'))
            tifffile.imwrite(save_p, vol.astype(np.float32))

            # è¯»å– GT stack å¹¶å½’ä¸€åŒ–
            gt_p = os.path.join(config.VALID.gt_path, names[idx].replace('.npy', '.tif'))
            if os.path.exists(gt_p):
                gt_vol = tifffile.imread(gt_p).astype(np.float32)
                gt_vol = gt_vol / np.max(gt_vol)
                # â€”â€” æ–°å¢ï¼šå¦‚æœ gt_vol æ˜¯ (D,H,W)ï¼Œå°±è½¬æˆ (H,W,D)ï¼Œå¦åˆ™ä¿æŒä¸å˜ â€”â€” 
                if gt_vol.ndim == 3 and gt_vol.shape[0] == vol.shape[-1]:
                    gt_vol = np.transpose(gt_vol, (1,2,0))
                    print(f"[DEBUG] Transposed gt_vol to shape {gt_vol.shape}")

                psnrs, ssims = [], []
                for z in range(vol.shape[-1]):
                    gt_slice   = gt_vol[..., z]    # ç°åœ¨ä¸€å®šæ˜¯ (H, W)
                    pred_slice = vol[...,   z]     # (H, W)
                    # è·³è¿‡çº¯èƒŒæ™¯åˆ‡ç‰‡
                    if gt_slice.max() < 1e-6:
                        continue
                    psnrs.append(calculate_psnr( gt_slice, pred_slice, data_range=1.0))
                    ssims.append(calculate_ssim(gt_slice, pred_slice, data_range=1.0))
                avg_psnr = float(np.mean(psnrs)) if psnrs else float('nan')
                avg_ssim = float(np.mean(ssims)) if ssims else float('nan')
            else:
                avg_psnr = avg_ssim = float('nan')

            logf.write(f"{names[idx]}  PSNR:{avg_psnr:.4f}  SSIM:{avg_ssim:.4f}\n")
            print(f"\r[{idx+1}/{len(valid_imgs)}] PSNR:{avg_psnr:.2f} dB, SSIM:{avg_ssim:.4f}", end='')

    print(f"\nâœ… æ¨ç†å®Œæˆï¼Œæ—¥å¿—ä¿å­˜åœ¨ï¼š{log_path}")

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='F-VCD æ¨ç†ä¸è¯„ä¼°è„šæœ¬')
    parser.add_argument('-c', '--ckpt',  type=int, default=0, help='0 è¡¨ç¤º bestï¼Œå¦åˆ™è¡¨ç¤º epoch ç¼–å·')
    parser.add_argument('-b', '--batch', type=int, default=1, help='æ¨ç†æ—¶ batch size')
    args = parser.parse_args()
    infer(epoch=args.ckpt, batch_size=args.batch)
